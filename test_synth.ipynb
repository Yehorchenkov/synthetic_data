{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test synthetic data and choose best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, plot_roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name_from_file(file_name: str) -> str:\n",
    "    \"\"\"\n",
    "    returns model name parset from file name\n",
    "    file_name: str. Template is df_synth_XXX.csv, where XXX - model name    \n",
    "    \"\"\"\n",
    "    return file_name.\\\n",
    "                split('.')[0].\\\n",
    "                split('_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_dict(file_list: list) -> dict:\n",
    "    \"\"\"\n",
    "    reads csv files to dict. Model name is key, dataframe is value.        \n",
    "    \"\"\"\n",
    "    data = dict()\n",
    "    for file_name in file_list:\n",
    "        model_name = model_name_from_file(file_name)\n",
    "        df = pd.read_csv(file_name, index_col=0)\n",
    "        data[model_name] = df\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read synthetic data\n",
    "list_df = ['df_synth_CopulaGAN.csv', 'df_synth_CTGAN.csv', 'df_synth_GaussianCopula.csv', 'df_synth_TVAE.csv']\n",
    "df_synth_dict = read_csv_to_dict(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read real data\n",
    "df_test = pd.read_csv('test_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "cat_cols = ['GROUP', 'CATEGORY', 'PM NAME', 'SPONSOR NAME']\n",
    "\n",
    "# Converting categorical columns to type 'category'\n",
    "for name, df in df_synth_dict.items():\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype('category')\n",
    "    \n",
    "# the same for validation data\n",
    "for c in cat_cols:\n",
    "    df_test[c] = df_test[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing. OneHotEncoder for categorical columns\n",
    "ohe = OneHotEncoder(sparse = False, handle_unknown = \"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [('cat', ohe, cat_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model estimation we will use crossvalidation and roc-auc metric\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "# Logistic regression\n",
    "lr = LogisticRegression(penalty='l2', C=0.1)\n",
    "clf_lr = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                    ('classifier', lr)])\n",
    "    \n",
    "# Random forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "clf_rf = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                    ('classifier', rf)])\n",
    "    \n",
    "#XGBoost\n",
    "xgb = XGBClassifier(max_depth=2, gamma=2, eta=0.8, reg_alpha=0.5, reg_lambda=0.5)\n",
    "clf_xgb = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                    ('classifier', xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with models\n",
    "models_dict = {'Logistic Regression': clf_lr,\n",
    "               'Random Forest': clf_rf,\n",
    "               'XGBoost': clf_xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(models: dict, X_train: pd.DataFrame, y_train: pd.DataFrame) -> pd.DataFrame:\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "        names.append(name)\n",
    "        results.append(scores.mean())\n",
    "    \n",
    "    return pd.DataFrame([results], columns=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate synthetic data, obtained from different models, by different metrics\n",
    "def exp_run(models: dict, synth_data: dict) -> pd.DataFrame:\n",
    "    names = []\n",
    "    results = []\n",
    "    for name, sdata in synth_data.items():\n",
    "        # Split dataset into matrix X with features and vector y with target\n",
    "        X_train, y_train = sdata.drop(['AUTHORIZATION'], axis=1), sdata['AUTHORIZATION']\n",
    "        \n",
    "        # Evaluate model  \n",
    "        results.append(get_metric(models, X_train, y_train))\n",
    "        names.append(name)\n",
    "                \n",
    "    return pd.concat(results).set_axis(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CopulaGAN</th>\n",
       "      <td>0.562147</td>\n",
       "      <td>0.518634</td>\n",
       "      <td>0.547211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTGAN</th>\n",
       "      <td>0.515435</td>\n",
       "      <td>0.494390</td>\n",
       "      <td>0.513854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianCopula</th>\n",
       "      <td>0.609563</td>\n",
       "      <td>0.576024</td>\n",
       "      <td>0.586107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVAE</th>\n",
       "      <td>0.967677</td>\n",
       "      <td>0.968398</td>\n",
       "      <td>0.971965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Logistic Regression  Random Forest   XGBoost\n",
       "CopulaGAN                  0.562147       0.518634  0.547211\n",
       "CTGAN                      0.515435       0.494390  0.513854\n",
       "GaussianCopula             0.609563       0.576024  0.586107\n",
       "TVAE                       0.967677       0.968398  0.971965"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_run(models_dict, df_synth_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best synthetic model is TVAE. Let's validate this model on real data.\n",
    "\n",
    "The best ML model is XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into matrix X with features and vector y with target\n",
    "\n",
    "# test data\n",
    "X_train, y_train = df_synth_dict['TVAE'].drop(['AUTHORIZATION'], axis=1), df_synth_dict['TVAE']['AUTHORIZATION']\n",
    "\n",
    "# validation data\n",
    "X_test, y_test = df_test.drop(['AUTHORIZATION'], axis = 1), df_test['AUTHORIZATION']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['GROUP', 'CATEGORY',\n",
       "                                                   'PM NAME',\n",
       "                                                   'SPONSOR NAME'])])),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(eta=0.8, gamma=2, max_depth=2, reg_alpha=0.5,\n",
       "                               reg_lambda=0.5))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdout = clf_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred_holdout)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
